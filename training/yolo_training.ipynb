{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc91afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50944206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"lattPIhNAlOdOqrvYSrY\")\n",
    "project = rf.workspace(\"yolo-train-mcoio\").project(\"head-detection-v2\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3709b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Desktop\\\\FYP Project\\\\Watchly.AI\\\\training\\\\Head-Detection-V2-1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80c9d42",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\conda_venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\conda_venv\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\conda_venv\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\conda_venv\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 909, in entrypoint\n",
      "    check_dict_alignment(full_args_dict, {a: \"\"})\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\conda_venv\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 497, in check_dict_alignment\n",
      "    raise SyntaxError(string + CLI_HELP_MSG) from e\n",
      "SyntaxError: '\u001b[31m\u001b[1mProject\\Watchly.AI\\training\\Head-Detection-V2-1\\\\data.yaml\u001b[0m' is not a valid YOLO argument. \n",
      "\n",
      "    Arguments received: ['yolo', 'detect', 'train', 'data=c:\\\\Users\\\\User\\\\Desktop\\\\FYP', 'Project\\\\Watchly.AI\\\\training\\\\Head-Detection-V2-1\\\\\\\\data.yaml', 'model=yolo11s.pt', 'epochs=150', 'project=yolo11_head_detection', 'name=run1']. Ultralytics 'yolo' commands use the following syntax:\n",
      "\n",
      "        yolo TASK MODE ARGS\n",
      "\n",
      "        Where   TASK (optional) is one of frozenset({'detect', 'obb', 'classify', 'pose', 'segment'})\n",
      "                MODE (required) is one of frozenset({'train', 'benchmark', 'track', 'export', 'val', 'predict'})\n",
      "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
      "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
      "\n",
      "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
      "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
      "\n",
      "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
      "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
      "\n",
      "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
      "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
      "\n",
      "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
      "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
      "\n",
      "    5. Ultralytics solutions usage\n",
      "        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n",
      "\n",
      "    6. Run special commands:\n",
      "        yolo help\n",
      "        yolo checks\n",
      "        yolo version\n",
      "        yolo settings\n",
      "        yolo copy-cfg\n",
      "        yolo cfg\n",
      "        yolo solutions help\n",
      "\n",
      "    Docs: https://docs.ultralytics.com\n",
      "    Solutions: https://docs.ultralytics.com/solutions/\n",
      "    Community: https://community.ultralytics.com\n",
      "    GitHub: https://github.com/ultralytics/ultralytics\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!yolo detect train data={dataset.location}\\\\data.yaml model=yolo11s.pt epochs=150 project=yolo11_head_detection name=run1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
